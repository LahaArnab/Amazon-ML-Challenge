{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv(\"FullData_train_with_image_name.xlsx - train_with_image_name.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   sample_id              75000 non-null  int64  \n",
      " 1   catalog_content        75000 non-null  object \n",
      " 2   brand_name             69729 non-null  object \n",
      " 3   descriptions           32533 non-null  object \n",
      " 4   benefits               60720 non-null  object \n",
      " 5   values                 75000 non-null  object \n",
      " 6   units                  74059 non-null  object \n",
      " 7   pack_of                19707 non-null  float64\n",
      " 8   item_name              74994 non-null  object \n",
      " 9   pack_of.1              26677 non-null  float64\n",
      " 10  image_link             75000 non-null  object \n",
      " 11  price                  75000 non-null  float64\n",
      " 12  downloaded_image_name  75000 non-null  object \n",
      "dtypes: float64(3), int64(1), object(9)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import Libraries ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open_clip\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "\n",
    "# Suppress annoying but harmless warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Passing `palette` without `max_colors`\")\n",
    "\n",
    "# --- 2. Configuration & Setup ---\n",
    "class Config:\n",
    "    \"\"\"A centralized class for all hyperparameters and settings.\"\"\"\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    MODEL_NAME = 'ViT-B-32'\n",
    "    PRETRAINED_CHECKPOINT = 'laion2b_s34b_b79k'\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 5\n",
    "\n",
    "    # Differential Learning Rates for fine-tuning\n",
    "    CLIP_LR = 1e-6\n",
    "    HEAD_LR = 1e-4\n",
    "    WEIGHT_DECAY = 0.01\n",
    "\n",
    "    # Early Stopping parameters\n",
    "    PATIENCE = 3\n",
    "    MIN_DELTA = 0.001\n",
    "\n",
    "    # Paths (‚ö†Ô∏è IMPORTANT: Update this path if needed)\n",
    "    IMAGE_DIR = 'output_folder'\n",
    "\n",
    "print(f\"Using device: {Config.DEVICE}\")\n",
    "if not os.path.exists(Config.IMAGE_DIR):\n",
    "    raise FileNotFoundError(f\"Image directory not found: {Config.IMAGE_DIR}. Please check the path.\")\n",
    "\n",
    "# --- 3. Data Loading and Enhanced Feature Engineering ---\n",
    "\n",
    "# ‚ö†Ô∏è ===================================================================\n",
    "# ‚ö†Ô∏è IMPORTANT: Load your actual DataFrame 'df' here.\n",
    "# ‚ö†Ô∏è Example: df = pd.read_csv('path/to/your/data.csv')\n",
    "# ‚ö†Ô∏è ===================================================================\n",
    "# This block is a placeholder. Ensure your 'df' is loaded before this script runs.\n",
    "# For demonstration purposes, I will create a dummy DataFrame.\n",
    "# In your environment, you should already have 'df' loaded from your file.\n",
    "if 'df' not in locals():\n",
    "     raise NameError(\"DataFrame 'df' is not defined. Please load your data where indicated.\")\n",
    "\n",
    "# Add this line to see all your available column names\n",
    "print(f\"Available columns in your DataFrame: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "def create_comprehensive_description(row):\n",
    "    \"\"\"Combines multiple text fields into a single rich description for CLIP.\"\"\"\n",
    "    parts = []\n",
    "    # Add brand, item name, and general description for richer context\n",
    "    if pd.notna(row.get('brand_name')): parts.append(str(row['brand_name']))\n",
    "    if pd.notna(row.get('item_name')): parts.append(str(row['item_name']))\n",
    "    if pd.notna(row.get('descriptions')): parts.append(f\"Description: {row['descriptions']}\")\n",
    "\n",
    "    # This part is kept for generality, it won't find columns in your current df but won't error\n",
    "    attributes = [str(row[col]) for col in ['flavours_only', 'sizes_only', 'product_attributes'] if col in row and pd.notna(row[col])]\n",
    "    if attributes: parts.append(f\"Features: {', '.join(attributes)}.\")\n",
    "\n",
    "    if pd.notna(row.get('benefits')): parts.append(f\"Benefits: {row['benefits']}\")\n",
    "\n",
    "    return \" \".join(parts).replace(\"  \", \" \").strip()\n",
    "\n",
    "# --- Preprocessing for Numerical and Categorical Features ---\n",
    "# --- Preprocessing for Numerical and Categorical Features ---\n",
    "\n",
    "# ‚úÖ FIX: Strip leading/trailing whitespace from all column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Optional: Print the cleaned column names to verify\n",
    "print(\"Cleaned column names:\", df.columns.tolist())\n",
    "\n",
    "# ‚úÖ MODIFIED: Convert 'values' from object to a numeric type.\n",
    "# 'coerce' will turn any non-numeric values (like text) into NaN (Not a Number).\n",
    "df['values'] = pd.to_numeric(df['values'], errors='coerce')\n",
    "\n",
    "# Handle missing values before splitting.\n",
    "# For 'pack_of', assume NaN means a single item.\n",
    "# Handle missing values before splitting.\n",
    "df['pack_of'] = df['pack_of'].fillna(1.0).astype(float)\n",
    "\n",
    "# --- Idempotent 'units' processing ---\n",
    "# This check ensures this block only runs if the 'units' column exists.\n",
    "if 'units' in df.columns:\n",
    "    print(\"Processing 'units' column (one-hot encoding)...\")\n",
    "    # For 'units', fill NaN with 'unknown' to create a separate category.\n",
    "    df['units'] = df['units'].fillna('unknown').astype(str)\n",
    "    # This line removes the 'units' column and replaces it with one-hot encoded columns.\n",
    "    df = pd.get_dummies(df, columns=['units'], prefix='unit', dtype=float)\n",
    "else:\n",
    "    print(\"'units' column already processed. Skipping one-hot encoding.\")\n",
    "    \n",
    "# Apply text feature engineering\n",
    "df['description'] = df.apply(create_comprehensive_description, axis=1)\n",
    "\n",
    "# ... the rest of your code follows\n",
    "\n",
    "# ‚úÖ MODIFIED #1: Replaced 'YOUR_VALUE_COLUMN_NAME' with 'values' from your DataFrame.\n",
    "VALUE_COL = 'values'\n",
    "if VALUE_COL not in df.columns:\n",
    "    raise KeyError(f\"Column '{VALUE_COL}' not found in DataFrame. Please check the column name.\")\n",
    "\n",
    "\n",
    "# Define columns to be used\n",
    "unit_cols = [col for col in df.columns if col.startswith('unit_')]\n",
    "numerical_cols = [VALUE_COL, 'pack_of'] + unit_cols # This now correctly includes 'values'\n",
    "feature_cols = ['description', 'price', 'downloaded_image_name'] + numerical_cols\n",
    "\n",
    "df_processed = df[feature_cols].copy()\n",
    "df_processed['image_path'] = df_processed['downloaded_image_name'].apply(lambda x: os.path.join(Config.IMAGE_DIR, str(x)))\n",
    "\n",
    "# ‚úÖ MODIFIED #2: This line now correctly uses the 'values' column via the VALUE_COL variable.\n",
    "# It also drops rows where 'values' became NaN after the numeric conversion.\n",
    "df_processed.dropna(subset=['price', 'description', VALUE_COL], inplace=True)\n",
    "df_processed = df_processed[df_processed['description'] != '']\n",
    "\n",
    "print(f\"‚úÖ Created features. Total samples: {len(df_processed)}. Numerical/Categorical features: {numerical_cols}\")\n",
    "\n",
    "train_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "print(f\"Data split into {len(train_df)} training and {len(test_df)} testing samples.\")\n",
    "\n",
    "\n",
    "# --- 4. Dataset Class and DataLoaders ---\n",
    "\n",
    "class ProductPriceDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for loading product images, text, and numerical features.\"\"\"\n",
    "    def __init__(self, df, image_transform, tokenizer, numerical_cols, stats):\n",
    "        self.df = df.copy() # Use a copy to avoid SettingWithCopyWarning\n",
    "        self.image_transform = image_transform\n",
    "        self.tokenizer = tokenizer\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.stats = stats\n",
    "        self.value_col_name = numerical_cols[0] # Assumes the value column ('values') is the first one\n",
    "\n",
    "        # Pre-calculate normalized values for efficiency\n",
    "        for col in [self.value_col_name, 'pack_of']:\n",
    "            mean = self.stats[col]['mean']\n",
    "            std = self.stats[col]['std']\n",
    "            self.df[f'{col}_normalized'] = (self.df[col] - mean) / (std + 1e-6)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try:\n",
    "            image = self.image_transform(Image.open(row['image_path']).convert('RGB'))\n",
    "        except (FileNotFoundError, UnboundLocalError, OSError):\n",
    "            # Return None if image is missing or corrupt, will be handled by collate_fn\n",
    "            return None\n",
    "\n",
    "        text = self.tokenizer(row['description'])[0]\n",
    "        log_price = torch.tensor(np.log1p(row['price']), dtype=torch.float32)\n",
    "\n",
    "        # Create a single tensor for all numerical features\n",
    "        # ‚úÖ MODIFIED #3: This now correctly gets the normalized 'values' column.\n",
    "        norm_value = torch.tensor(row[f'{self.value_col_name}_normalized'], dtype=torch.float32)\n",
    "        norm_pack_of = torch.tensor(row['pack_of_normalized'], dtype=torch.float32)\n",
    "        unit_features = torch.tensor(row[[c for c in self.numerical_cols if c.startswith('unit_')]].values.astype(np.float32))\n",
    "        numerical_feats = torch.cat([norm_value.unsqueeze(0), norm_pack_of.unsqueeze(0), unit_features])\n",
    "\n",
    "        return {'image': image, 'text': text, 'numerical': numerical_feats, 'log_price': log_price}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function to filter out None values from the batch.\"\"\"\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch) if batch else None\n",
    "\n",
    "\n",
    "# --- 5. Model, Training, and Evaluation ---\n",
    "\n",
    "class CLIPPricePredictor(nn.Module):\n",
    "    \"\"\"The core model combining CLIP embeddings with numerical features.\"\"\"\n",
    "    def __init__(self, clip_model, numerical_feature_size, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.clip = clip_model\n",
    "        clip_embedding_dim = self.clip.text_projection.shape[1]\n",
    "        # The combined dimension now includes the size of our numerical feature vector\n",
    "        combined_dim = (clip_embedding_dim * 2) + numerical_feature_size\n",
    "\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, text, numerical_feats):\n",
    "        # Generate embeddings\n",
    "        with torch.no_grad(): # Freeze CLIP encoder during training head\n",
    "            image_features = self.clip.encode_image(image)\n",
    "            text_features = self.clip.encode_text(text)\n",
    "\n",
    "        # L2 Normalize embeddings - a standard practice for CLIP\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # Concatenate image, text, and the multi-dimensional numerical features\n",
    "        combined = torch.cat([image_features, text_features, numerical_feats], dim=1)\n",
    "\n",
    "        return self.regression_head(combined).squeeze(-1)\n",
    "\n",
    "class EarlyStopper:\n",
    "    \"\"\"Stops training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss, model):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            print(\"‚úÖ Validation loss decreased, saving model.\")\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"üõë Early stopping triggered!\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def calculate_smape(preds, targets):\n",
    "    \"\"\"Calculates Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "    numerator = torch.abs(preds - targets)\n",
    "    denominator = (torch.abs(targets) + torch.abs(preds)) / 2\n",
    "    # Add a small epsilon to avoid division by zero\n",
    "    return (torch.mean(numerator / (denominator + 1e-8)) * 100).item()\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, scheduler, loss_fn, config):\n",
    "    \"\"\"The main training and validation loop.\"\"\"\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_smape': []}\n",
    "    early_stopper = EarlyStopper(patience=config.PATIENCE, min_delta=config.MIN_DELTA)\n",
    "\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Training]\")\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            if batch is None: continue # Skip faulty batches\n",
    "\n",
    "            images = batch['image'].to(config.DEVICE)\n",
    "            texts = batch['text'].to(config.DEVICE)\n",
    "            numerical = batch['numerical'].to(config.DEVICE)\n",
    "            log_prices = batch['log_price'].to(config.DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_log_prices = model(images, texts, numerical)\n",
    "            loss = loss_fn(pred_log_prices, log_prices)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'log_huber_loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss, total_val_smape = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Validation]\"):\n",
    "                if batch is None: continue\n",
    "\n",
    "                images = batch['image'].to(config.DEVICE)\n",
    "                texts = batch['text'].to(config.DEVICE)\n",
    "                numerical = batch['numerical'].to(config.DEVICE)\n",
    "                log_prices = batch['log_price'].to(config.DEVICE)\n",
    "\n",
    "                pred_log_prices = model(images, texts, numerical)\n",
    "                total_val_loss += loss_fn(pred_log_prices, log_prices).item()\n",
    "\n",
    "                # Convert back from log scale to calculate SMAPE on actual prices\n",
    "                true_prices = torch.expm1(log_prices)\n",
    "                pred_prices = torch.expm1(pred_log_prices)\n",
    "                total_val_smape += calculate_smape(pred_prices, true_prices)\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_smape = total_val_smape / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_smape'].append(avg_val_smape)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{config.EPOCHS} -> Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val SMAPE: {avg_val_smape:.2f}% | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "        scheduler.step()\n",
    "        if early_stopper.early_stop(avg_val_loss, model):\n",
    "            break\n",
    "\n",
    "    print(\"Loading best model state from training.\")\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    return history, model\n",
    "\n",
    "\n",
    "# --- 6. Main Execution Block ---\n",
    "if __name__ == '__main__':\n",
    "    # Initialize CLIP model, tokenizer, and image transformations\n",
    "    clip_model, _, base_preprocess = open_clip.create_model_and_transforms(\n",
    "        Config.MODEL_NAME, pretrained=Config.PRETRAINED_CHECKPOINT, device=Config.DEVICE\n",
    "    )\n",
    "    tokenizer = open_clip.get_tokenizer(Config.MODEL_NAME)\n",
    "\n",
    "    # Add data augmentation for the training set to improve model generalization\n",
    "    train_preprocess = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        base_preprocess,\n",
    "    ])\n",
    "\n",
    "    # Calculate normalization stats ONLY from the training data to avoid data leakage\n",
    "    # ‚úÖ MODIFIED #4: This now correctly creates a dictionary key 'values' for the stats.\n",
    "    stats = {\n",
    "        VALUE_COL: {'mean': train_df[VALUE_COL].mean(), 'std': train_df[VALUE_COL].std()},\n",
    "        'pack_of': {'mean': train_df['pack_of'].mean(), 'std': train_df['pack_of'].std()}\n",
    "    }\n",
    "\n",
    "    train_dataset = ProductPriceDataset(train_df, train_preprocess, tokenizer, numerical_cols, stats)\n",
    "    test_dataset = ProductPriceDataset(test_df, base_preprocess, tokenizer, numerical_cols, stats)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    # Pass the correct number of numerical features to the model\n",
    "    NUMERICAL_FEATURE_SIZE = len(numerical_cols)\n",
    "    model = CLIPPricePredictor(clip_model, numerical_feature_size=NUMERICAL_FEATURE_SIZE).to(Config.DEVICE)\n",
    "    \n",
    "    # Freeze the CLIP model parameters initially\n",
    "    for param in model.clip.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Set up optimizer with differential learning rates\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': model.clip.parameters(), 'lr': Config.CLIP_LR},\n",
    "        {'params': model.regression_head.parameters(), 'lr': Config.HEAD_LR}\n",
    "    ], weight_decay=Config.WEIGHT_DECAY)\n",
    "\n",
    "    # HuberLoss is robust to outliers, which is common in price data\n",
    "    loss_fn = nn.HuberLoss()\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=Config.EPOCHS, eta_min=1e-8)\n",
    "\n",
    "    # Run the training and evaluation loop\n",
    "    training_history, best_model = train_and_evaluate(model, train_loader, test_loader, optimizer, scheduler, loss_fn, Config)\n",
    "\n",
    "    # --- 7. Plotting Results ---\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    epochs_ran = len(training_history['train_loss'])\n",
    "\n",
    "    ax1.plot(range(epochs_ran), training_history['train_loss'], label='Training Loss (Huber)', marker='o')\n",
    "    ax1.plot(range(epochs_ran), training_history['val_loss'], label='Validation Loss (Huber)', marker='o')\n",
    "    ax1.set_title('Training and Validation Loss', fontsize=14)\n",
    "    ax1.set_xlabel('Epochs'); ax1.set_ylabel('Loss'); ax1.legend(); ax1.grid(True)\n",
    "\n",
    "    ax2.plot(range(epochs_ran), training_history['val_smape'], label='Validation SMAPE', color='orange', marker='o')\n",
    "    ax2.set_title('Validation SMAPE', fontsize=14)\n",
    "    ax2.set_xlabel('Epochs'); ax2.set_ylabel('SMAPE (%)'); ax2.legend(); ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   sample_id              75000 non-null  int64  \n",
      " 1   catalog_content        75000 non-null  object \n",
      " 2   brand_name             69729 non-null  object \n",
      " 3   descriptions           32533 non-null  object \n",
      " 4   benefits               60720 non-null  object \n",
      " 5   values                 75000 non-null  object \n",
      " 6   units                  74059 non-null  object \n",
      " 7   pack_of                19707 non-null  float64\n",
      " 8   item_name              74994 non-null  object \n",
      " 9   pack_of.1              26677 non-null  float64\n",
      " 10  image_link             75000 non-null  object \n",
      " 11  price                  75000 non-null  float64\n",
      " 12  downloaded_image_name  75000 non-null  object \n",
      "dtypes: float64(3), int64(1), object(9)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CODE FOR 75K DATA TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open_clip\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "import json # Added for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Prediction Process ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model and configuration loaded.\n",
      "‚úÖ Input data preprocessed. Predicting on 395 samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e2fc33e94544268591a2f41e45ccbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inference complete.\n",
      "üéâ Predictions saved successfully to: my_new_predictions.csv\n",
      "Find your results in: my_new_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================================================================================\n",
    "# --- üöÄ NEW: Additional Functions for Saving and Prediction üöÄ ---\n",
    "# =========================================================================================\n",
    "\n",
    "def save_finetuned_model(model, stats, numerical_cols, save_path):\n",
    "    \"\"\"\n",
    "    Saves the fine-tuned model's state, normalization stats, and numerical column info.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained model object.\n",
    "        stats (dict): Dictionary containing mean/std for numerical columns.\n",
    "        numerical_cols (list): List of numerical column names used for training.\n",
    "        save_path (str): Path to save the model file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to hold everything needed for inference\n",
    "    model_package = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'stats': stats,\n",
    "        'numerical_cols': numerical_cols,\n",
    "        'config': {\n",
    "            'MODEL_NAME': Config.MODEL_NAME,\n",
    "            'PRETRAINED_CHECKPOINT': Config.PRETRAINED_CHECKPOINT\n",
    "        }\n",
    "    }\n",
    "    torch.save(model_package, save_path)\n",
    "    print(f\"‚úÖ Model package saved successfully to: {save_path}\")\n",
    "\n",
    "def predict_from_df(df_to_predict, model_path, output_csv_path=\"predictions.csv\"):\n",
    "    \"\"\"\n",
    "    Predicts prices for a given DataFrame using a saved fine-tuned model.\n",
    "    \n",
    "    Args:\n",
    "        df_to_predict (pd.DataFrame): DataFrame with the same structure as the training data.\n",
    "        model_path (str): Path to the saved model package (.pth file).\n",
    "        output_csv_path (str): Path to save the final CSV with predictions.\n",
    "        \n",
    "    Returns:\n",
    "        str: The path to the generated predictions CSV file.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Prediction Process ---\")\n",
    "    \n",
    "    # --- 1. Load Model and Configuration ---\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at: {model_path}\")\n",
    "        \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # ‚úÖ FIXED: Added weights_only=False to allow loading the full dictionary\n",
    "    model_package = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    model_config = model_package['config']\n",
    "    stats = model_package['stats']\n",
    "    numerical_cols_loaded = model_package['numerical_cols']\n",
    "    \n",
    "    # Initialize the base CLIP model and preprocessor\n",
    "    clip_model, _, base_preprocess = open_clip.create_model_and_transforms(\n",
    "        model_config['MODEL_NAME'], pretrained=model_config['PRETRAINED_CHECKPOINT'], device=device\n",
    "    )\n",
    "    tokenizer = open_clip.get_tokenizer(model_config['MODEL_NAME'])\n",
    "    \n",
    "    # Initialize our custom model architecture and load the saved weights\n",
    "    NUMERICAL_FEATURE_SIZE = len(numerical_cols_loaded)\n",
    "    prediction_model = CLIPPricePredictor(clip_model, numerical_feature_size=NUMERICAL_FEATURE_SIZE).to(device)\n",
    "    prediction_model.load_state_dict(model_package['model_state_dict'])\n",
    "    prediction_model.eval() # Set model to evaluation mode\n",
    "    \n",
    "    print(\"‚úÖ Model and configuration loaded.\")\n",
    "\n",
    "    # --- 2. Preprocess the Input DataFrame ---\n",
    "    # Ensure the global 'unit_cols' from training is used for consistent one-hot encoding\n",
    "    global unit_cols\n",
    "    unit_cols = [col for col in numerical_cols_loaded if col.startswith('unit_')]\n",
    "    \n",
    "    df_pred_processed = preprocess_dataframe(df_to_predict)\n",
    "    \n",
    "    # Filter out any rows that have missing essential data after preprocessing\n",
    "    df_pred_processed.dropna(subset=['description', 'values'], inplace=True)\n",
    "    df_pred_processed = df_pred_processed[df_pred_processed['description'] != '']\n",
    "    \n",
    "    # Store sample_ids to merge back later, ensuring order is maintained\n",
    "    original_sample_ids = df_pred_processed['sample_id'].tolist()\n",
    "    \n",
    "    print(f\"‚úÖ Input data preprocessed. Predicting on {len(df_pred_processed)} samples.\")\n",
    "\n",
    "    # --- 3. Create Dataset and DataLoader ---\n",
    "    pred_dataset = ProductPriceDataset(\n",
    "        df_pred_processed, \n",
    "        base_preprocess, \n",
    "        tokenizer, \n",
    "        numerical_cols_loaded, \n",
    "        stats,\n",
    "        is_predict=True # Set flag to not look for 'price' column\n",
    "    )\n",
    "    \n",
    "    pred_loader = DataLoader(\n",
    "        pred_dataset, \n",
    "        batch_size=Config.BATCH_SIZE * 2, # Use a larger batch size for faster inference\n",
    "        shuffle=False, \n",
    "        num_workers=Config.NUM_WORKERS, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # --- 4. Run Inference ---\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(pred_loader, desc=\"Generating Predictions\"):\n",
    "            if batch is None: continue\n",
    "            \n",
    "            images = batch['image'].to(device)\n",
    "            texts = batch['text'].to(device)\n",
    "            numerical = batch['numerical'].to(device)\n",
    "            \n",
    "            pred_log_prices = prediction_model(images, texts, numerical)\n",
    "            \n",
    "            # Convert log prices back to actual prices\n",
    "            pred_prices = torch.expm1(pred_log_prices).cpu().numpy()\n",
    "            all_predictions.extend(pred_prices)\n",
    "    \n",
    "    print(\"‚úÖ Inference complete.\")\n",
    "\n",
    "    # --- 5. Format and Save Output ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'sample_id': original_sample_ids,\n",
    "        'price': all_predictions\n",
    "    })\n",
    "    \n",
    "    # Format the price to two decimal places\n",
    "    results_df['price'] = results_df['price'].round(2)\n",
    "    \n",
    "    results_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"üéâ Predictions saved successfully to: {output_csv_path}\")\n",
    "    \n",
    "    return output_csv_path\n",
    "\n",
    "# Example of how you would use the prediction function (do not run this part during training)\n",
    "if __name__ == '__main__':\n",
    "    # ... (after training completes and model is saved) ...\n",
    "    \n",
    "    # 1. Load a new DataFrame you want to predict prices for\n",
    "    # new_data_df = pd.read_csv('path/to/your/new_data.csv')\n",
    "    new_data_df = df\n",
    "    \n",
    "    # 2. Define the path to your saved model\n",
    "    saved_model_path = 'final_clip_price_model.pth'\n",
    "    \n",
    "    # 3. Call the prediction function\n",
    "    prediction_csv_file = predict_from_df(new_data_df, saved_model_path, output_csv_path=\"my_new_predictions.csv\")\n",
    "    \n",
    "    print(f\"Find your results in: {prediction_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================================================\n",
    "# --- üöÄ NEW: Additional Functions for Saving and Prediction üöÄ ---\n",
    "# =========================================================================================\n",
    "\n",
    "def save_finetuned_model(model, stats, numerical_cols, save_path):\n",
    "    \"\"\"\n",
    "    Saves the fine-tuned model's state, normalization stats, and numerical column info.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained model object.\n",
    "        stats (dict): Dictionary containing mean/std for numerical columns.\n",
    "        numerical_cols (list): List of numerical column names used for training.\n",
    "        save_path (str): Path to save the model file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to hold everything needed for inference\n",
    "    model_package = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'stats': stats,\n",
    "        'numerical_cols': numerical_cols,\n",
    "        'config': {\n",
    "            'MODEL_NAME': Config.MODEL_NAME,\n",
    "            'PRETRAINED_CHECKPOINT': Config.PRETRAINED_CHECKPOINT\n",
    "        }\n",
    "    }\n",
    "    torch.save(model_package, save_path)\n",
    "    print(f\"‚úÖ Model package saved successfully to: {save_path}\")\n",
    "\n",
    "def predict_from_df(df_to_predict, model_path, output_csv_path=\"predictions.csv\"):\n",
    "    \"\"\"\n",
    "    Predicts prices for a given DataFrame using a saved fine-tuned model.\n",
    "    \n",
    "    Args:\n",
    "        df_to_predict (pd.DataFrame): DataFrame with the same structure as the training data.\n",
    "        model_path (str): Path to the saved model package (.pth file).\n",
    "        output_csv_path (str): Path to save the final CSV with predictions.\n",
    "        \n",
    "    Returns:\n",
    "        str: The path to the generated predictions CSV file.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Prediction Process ---\")\n",
    "    \n",
    "    # --- 1. Load Model and Configuration ---\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at: {model_path}\")\n",
    "        \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # ‚úÖ FIXED: Added weights_only=False to allow loading the full dictionary\n",
    "    model_package = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    model_config = model_package['config']\n",
    "    stats = model_package['stats']\n",
    "    numerical_cols_loaded = model_package['numerical_cols']\n",
    "    \n",
    "    # Initialize the base CLIP model and preprocessor\n",
    "    clip_model, _, base_preprocess = open_clip.create_model_and_transforms(\n",
    "        model_config['MODEL_NAME'], pretrained=model_config['PRETRAINED_CHECKPOINT'], device=device\n",
    "    )\n",
    "    tokenizer = open_clip.get_tokenizer(model_config['MODEL_NAME'])\n",
    "    \n",
    "    # Initialize our custom model architecture and load the saved weights\n",
    "    NUMERICAL_FEATURE_SIZE = len(numerical_cols_loaded)\n",
    "    prediction_model = CLIPPricePredictor(clip_model, numerical_feature_size=NUMERICAL_FEATURE_SIZE).to(device)\n",
    "    prediction_model.load_state_dict(model_package['model_state_dict'])\n",
    "    prediction_model.eval() # Set model to evaluation mode\n",
    "    \n",
    "    print(\"‚úÖ Model and configuration loaded.\")\n",
    "\n",
    "    # --- 2. Preprocess the Input DataFrame ---\n",
    "    # Ensure the global 'unit_cols' from training is used for consistent one-hot encoding\n",
    "    global unit_cols\n",
    "    unit_cols = [col for col in numerical_cols_loaded if col.startswith('unit_')]\n",
    "    \n",
    "    df_pred_processed = preprocess_dataframe(df_to_predict)\n",
    "    \n",
    "    # Filter out any rows that have missing essential data after preprocessing\n",
    "    df_pred_processed.dropna(subset=['description', 'values'], inplace=True)\n",
    "    df_pred_processed = df_pred_processed[df_pred_processed['description'] != '']\n",
    "    \n",
    "    # Store sample_ids to merge back later, ensuring order is maintained\n",
    "    original_sample_ids = df_pred_processed['sample_id'].tolist()\n",
    "    \n",
    "    print(f\"‚úÖ Input data preprocessed. Predicting on {len(df_pred_processed)} samples.\")\n",
    "\n",
    "    # --- 3. Create Dataset and DataLoader ---\n",
    "    pred_dataset = ProductPriceDataset(\n",
    "        df_pred_processed, \n",
    "        base_preprocess, \n",
    "        tokenizer, \n",
    "        numerical_cols_loaded, \n",
    "        stats,\n",
    "        is_predict=True # Set flag to not look for 'price' column\n",
    "    )\n",
    "    \n",
    "    pred_loader = DataLoader(\n",
    "        pred_dataset, \n",
    "        batch_size=Config.BATCH_SIZE * 2, # Use a larger batch size for faster inference\n",
    "        shuffle=False, \n",
    "        num_workers=Config.NUM_WORKERS, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # --- 4. Run Inference ---\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(pred_loader, desc=\"Generating Predictions\"):\n",
    "            if batch is None: continue\n",
    "            \n",
    "            images = batch['image'].to(device)\n",
    "            texts = batch['text'].to(device)\n",
    "            numerical = batch['numerical'].to(device)\n",
    "            \n",
    "            pred_log_prices = prediction_model(images, texts, numerical)\n",
    "            \n",
    "            # Convert log prices back to actual prices\n",
    "            pred_prices = torch.expm1(pred_log_prices).cpu().numpy()\n",
    "            all_predictions.extend(pred_prices)\n",
    "    \n",
    "    print(\"‚úÖ Inference complete.\")\n",
    "\n",
    "    # --- 5. Format and Save Output ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'sample_id': original_sample_ids,\n",
    "        'price': all_predictions\n",
    "    })\n",
    "    \n",
    "    # Format the price to two decimal places\n",
    "    results_df['price'] = results_df['price'].round(2)\n",
    "    \n",
    "    results_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"üéâ Predictions saved successfully to: {output_csv_path}\")\n",
    "    \n",
    "    return output_csv_path\n",
    "\n",
    "# Example of how you would use the prediction function (do not run this part during training)\n",
    "if __name__ == '__main__':\n",
    "    # ... (after training completes and model is saved) ...\n",
    "    \n",
    "    # 1. Load a new DataFrame you want to predict prices for\n",
    "    # new_data_df = pd.read_csv('path/to/your/new_data.csv')\n",
    "    new_data_df = df\n",
    "    \n",
    "    # 2. Define the path to your saved model\n",
    "    saved_model_path = 'final_clip_price_model.pth'\n",
    "    \n",
    "    # 3. Call the prediction function\n",
    "    prediction_csv_file = predict_from_df(new_data_df, saved_model_path, output_csv_path=\"my_new_predictions.csv\")\n",
    "    \n",
    "    print(f\"Find your results in: {prediction_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_df(df_to_predict, model_path, output_csv_path=\"predictions.csv\"):\n",
    "    \"\"\"\n",
    "    Predicts prices for a given DataFrame using a saved fine-tuned model.\n",
    "    \n",
    "    Args:\n",
    "        df_to_predict (pd.DataFrame): DataFrame with the same structure as the training data.\n",
    "        model_path (str): Path to the saved model package (.pth file).\n",
    "        output_csv_path (str): Path to save the final CSV with predictions.\n",
    "        \n",
    "    Returns:\n",
    "        str: The path to the generated predictions CSV file.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Prediction Process ---\")\n",
    "    \n",
    "    # --- 1. Load Model and Configuration ---\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at: {model_path}\")\n",
    "        \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # ‚úÖ FIXED: Added weights_only=False to allow loading the full dictionary\n",
    "    model_package = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    model_config = model_package['config']\n",
    "    stats = model_package['stats']\n",
    "    numerical_cols_loaded = model_package['numerical_cols']\n",
    "    \n",
    "    # Initialize the base CLIP model and preprocessor\n",
    "    clip_model, _, base_preprocess = open_clip.create_model_and_transforms(\n",
    "        model_config['MODEL_NAME'], pretrained=model_config['PRETRAINED_CHECKPOINT'], device=device\n",
    "    )\n",
    "    tokenizer = open_clip.get_tokenizer(model_config['MODEL_NAME'])\n",
    "    \n",
    "    # Initialize our custom model architecture and load the saved weights\n",
    "    NUMERICAL_FEATURE_SIZE = len(numerical_cols_loaded)\n",
    "    prediction_model = CLIPPricePredictor(clip_model, numerical_feature_size=NUMERICAL_FEATURE_SIZE).to(device)\n",
    "    prediction_model.load_state_dict(model_package['model_state_dict'])\n",
    "    prediction_model.eval() # Set model to evaluation mode\n",
    "    \n",
    "    print(\"‚úÖ Model and configuration loaded.\")\n",
    "\n",
    "    # --- 2. Preprocess the Input DataFrame ---\n",
    "    # Ensure the global 'unit_cols' from training is used for consistent one-hot encoding\n",
    "    global unit_cols\n",
    "    unit_cols = [col for col in numerical_cols_loaded if col.startswith('unit_')]\n",
    "    \n",
    "    df_pred_processed = preprocess_dataframe(df_to_predict)\n",
    "    \n",
    "    # Filter out any rows that have missing essential data after preprocessing\n",
    "    df_pred_processed.dropna(subset=['description', 'values'], inplace=True)\n",
    "    df_pred_processed = df_pred_processed[df_pred_processed['description'] != '']\n",
    "    \n",
    "    # Store sample_ids to merge back later, ensuring order is maintained\n",
    "    original_sample_ids = df_pred_processed['sample_id'].tolist()\n",
    "    \n",
    "    print(f\"‚úÖ Input data preprocessed. Predicting on {len(df_pred_processed)} samples.\")\n",
    "\n",
    "    # --- 3. Create Dataset and DataLoader ---\n",
    "    pred_dataset = ProductPriceDataset(\n",
    "        df_pred_processed, \n",
    "        base_preprocess, \n",
    "        tokenizer, \n",
    "        numerical_cols_loaded, \n",
    "        stats,\n",
    "        is_predict=True # Set flag to not look for 'price' column\n",
    "    )\n",
    "    \n",
    "    pred_loader = DataLoader(\n",
    "        pred_dataset, \n",
    "        batch_size=Config.BATCH_SIZE * 2, # Use a larger batch size for faster inference\n",
    "        shuffle=False, \n",
    "        num_workers= Config.NUM_WORKERS , \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # --- 4. Run Inference ---\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(pred_loader, desc=\"Generating Predictions\"):\n",
    "            if batch is None: continue\n",
    "            \n",
    "            images = batch['image'].to(device)\n",
    "            texts = batch['text'].to(device)\n",
    "            numerical = batch['numerical'].to(device)\n",
    "            \n",
    "            pred_log_prices = prediction_model(images, texts, numerical)\n",
    "            \n",
    "            # Convert log prices back to actual prices\n",
    "            pred_prices = torch.expm1(pred_log_prices).cpu().numpy()\n",
    "            all_predictions.extend(pred_prices)\n",
    "    \n",
    "    print(\"‚úÖ Inference complete.\")\n",
    "\n",
    "    # --- 5. Format and Save Output ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'sample_id': original_sample_ids,\n",
    "        'price': all_predictions\n",
    "    })\n",
    "    \n",
    "    # Format the price to two decimal places\n",
    "    results_df['price'] = results_df['price'].round(2)\n",
    "    \n",
    "    results_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"üéâ Predictions saved successfully to: {output_csv_path}\")\n",
    "    \n",
    "    return output_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPPricePredictor(nn.Module):\n",
    "    \"\"\"The core model combining CLIP embeddings with numerical features.\"\"\"\n",
    "    def __init__(self, clip_model, numerical_feature_size, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.clip = clip_model\n",
    "        clip_embedding_dim = self.clip.text_projection.shape[1]\n",
    "        combined_dim = (clip_embedding_dim * 2) + numerical_feature_size\n",
    "\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, text, numerical_feats):\n",
    "        with torch.no_grad():\n",
    "            image_features = self.clip.encode_image(image)\n",
    "            text_features = self.clip.encode_text(text)\n",
    "\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        combined = torch.cat([image_features, text_features, numerical_feats], dim=1)\n",
    "        return self.regression_head(combined).squeeze(-1)\n",
    "\n",
    "class EarlyStopper:\n",
    "    \"\"\"Stops training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss, model):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            print(\"‚úÖ Validation loss decreased, saving model checkpoint.\")\n",
    "            torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"üõë Early stopping triggered!\")\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # ... (after training completes and model is saved) ...\n",
    "    \n",
    "    # 1. Load a new DataFrame you want to predict prices for\n",
    "    # new_data_df = pd.read_csv('path/to/your/new_data.csv')\n",
    "    new_data_df = df\n",
    "    # 2. Define the path to your saved model\n",
    "    saved_model_path = 'final_clip_price_model.pth'\n",
    "    \n",
    "    # 3. Call the prediction function\n",
    "    prediction_csv_file = predict_from_df(new_data_df, saved_model_path, output_csv_path=\"my_new_predictions.csv\")\n",
    "    \n",
    "    print(f\"Find your results in: {prediction_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   sample_id              75000 non-null  int64 \n",
      " 1   catalog_content        75000 non-null  object\n",
      " 2   product_description    32710 non-null  object\n",
      " 3   values_only            73991 non-null  object\n",
      " 4   units_only             73988 non-null  object\n",
      " 5   product_attributes     39304 non-null  object\n",
      " 6   pack_of                19651 non-null  object\n",
      " 7   Item_name              75000 non-null  object\n",
      " 8   ingredients_only       7372 non-null   object\n",
      " 9   falvors_only           36372 non-null  object\n",
      " 10  country_origin         2681 non-null   object\n",
      " 11  benefits               60724 non-null  object\n",
      " 12  brand_name             74136 non-null  object\n",
      " 13  image_link             75000 non-null  object\n",
      " 14  downloaded_image_name  75000 non-null  object\n",
      "dtypes: int64(1), object(14)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"test_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   sample_id              75000 non-null  int64 \n",
      " 1   catalog_content        75000 non-null  object\n",
      " 2   product_description    32710 non-null  object\n",
      " 3   values_only            73991 non-null  object\n",
      " 4   units_only             73988 non-null  object\n",
      " 5   product_attributes     39304 non-null  object\n",
      " 6   pack_of                19651 non-null  object\n",
      " 7   Item_name              75000 non-null  object\n",
      " 8   ingredients_only       7372 non-null   object\n",
      " 9   falvors_only           36372 non-null  object\n",
      " 10  country_origin         2681 non-null   object\n",
      " 11  benefits               60724 non-null  object\n",
      " 12  brand_name             74136 non-null  object\n",
      " 13  image_link             75000 non-null  object\n",
      " 14  downloaded_image_name  75000 non-null  object\n",
      "dtypes: int64(1), object(14)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sample_id', 'catalog_content', 'product_description', 'values_only',\n",
      "       'units_only', 'product_attributes', 'pack_of', 'item_name',\n",
      "       'ingredients_only', 'flavors_only', 'country_origin', 'benefits',\n",
      "       'brand_name', 'image_link', 'downloaded_image_name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename specific columns and correct the typo\n",
    "df.rename(columns={\n",
    "    'Item_name': 'item_name',\n",
    "    'falvors_only': 'flavors_only', # Correcting the typo\n",
    "    'brand_name': 'brand_name'\n",
    "}, inplace=True)\n",
    "\n",
    "# Display the new column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'values_only': 'values'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'product_description': 'descriptions',\n",
    "    'values_only': 'values',\n",
    "    # 'units_only': 'units', # Not in the target list, so we'll drop or ignore\n",
    "    # 'product_attributes': 'attributes', # Not in the target list\n",
    "    'Item_name': 'item_name', # Correcting case\n",
    "    # 'ingredients_only': 'ingredients', # Not in the target list\n",
    "    'falvors_only': 'flavors', # Correcting typo and shortening, though 'flavors' is not in target list\n",
    "    # 'country_origin': 'country', # Not in the target list\n",
    "}\n",
    "\n",
    "df.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import Libraries ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open_clip\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "import json # Added for saving stats\n",
    "\n",
    "# Suppress annoying but harmless warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Passing `palette` without `max_colors`\")\n",
    "\n",
    "# --- 2. Configuration & Setup ---\n",
    "class Config:\n",
    "    \"\"\"A centralized class for all hyperparameters and settings.\"\"\"\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    MODEL_NAME = 'ViT-B-32'\n",
    "    PRETRAINED_CHECKPOINT = 'laion2b_s34b_b79k'\n",
    "    \n",
    "    # Adjusted for a larger dataset\n",
    "    BATCH_SIZE = 128 # Can be increased based on GPU VRAM\n",
    "    EPOCHS = 2 # With more data, more epochs can be beneficial; EarlyStopping will prevent overfitting.\n",
    "    NUM_WORKERS = 0 # Use more CPU cores to load data faster\n",
    "\n",
    "    # Differential Learning Rates for fine-tuning\n",
    "    CLIP_LR = 1e-6\n",
    "    HEAD_LR = 1e-4\n",
    "    WEIGHT_DECAY = 0.01\n",
    "\n",
    "    # Early Stopping parameters\n",
    "    PATIENCE = 3\n",
    "    MIN_DELTA = 0.001\n",
    "\n",
    "    # Paths (‚ö†Ô∏è IMPORTANT: Update this path if needed)\n",
    "    # IMAGE_DIR = 'all_images_training_75k_new'\n",
    "    # MODEL_SAVE_PATH = 'final_clip_price_model.pth' # Path for the final model\n",
    "\n",
    "# print(f\"Using device: {Config.DEVICE}\")\n",
    "# if not os.path.exists(Config.IMAGE_DIR):\n",
    "#     raise FileNotFoundError(f\"Image directory not found: {Config.IMAGE_DIR}. Please check the path.\")\n",
    "\n",
    "# --- 3. Data Loading and Enhanced Feature Engineering ---\n",
    "\n",
    "# ‚ö†Ô∏è ===================================================================\n",
    "# ‚ö†Ô∏è IMPORTANT: Load your actual DataFrame 'df' here.\n",
    "# ‚ö†Ô∏è Example: df = pd.read_csv('path/to/your/data.csv')\n",
    "# ‚ö†Ô∏è ===================================================================\n",
    "# This block is a placeholder. Ensure your 'df' is loaded before this script runs.\n",
    "# For demonstration purposes, I will create a dummy DataFrame.\n",
    "# In your environment, you should already have 'df' loaded from your file.\n",
    "# if 'df' not in locals():\n",
    "#      raise NameError(\"DataFrame 'df' is not defined. Please load your data where indicated.\")\n",
    "\n",
    "# Add this line to see all your available column names\n",
    "# print(f\"Available columns in your DataFrame: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "def create_comprehensive_description(row):\n",
    "    \"\"\"Combines multiple text fields into a single rich description for CLIP.\"\"\"\n",
    "    parts = []\n",
    "    # Add brand, item name, and general description for richer context\n",
    "    if pd.notna(row.get('brand_name')): parts.append(str(row['brand_name']))\n",
    "    if pd.notna(row.get('item_name')): parts.append(str(row['item_name']))\n",
    "    if pd.notna(row.get('descriptions')): parts.append(f\"Description: {row['descriptions']}\")\n",
    "\n",
    "    # This part is kept for generality, it won't find columns in your current df but won't error\n",
    "    attributes = [str(row[col]) for col in ['flavours_only', 'sizes_only', 'product_attributes'] if col in row and pd.notna(row[col])]\n",
    "    if attributes: parts.append(f\"Features: {', '.join(attributes)}.\")\n",
    "\n",
    "    if pd.notna(row.get('benefits')): parts.append(f\"Benefits: {row['benefits']}\")\n",
    "\n",
    "    return \" \".join(parts).replace(\"  \", \" \").strip()\n",
    "\n",
    "def preprocess_dataframe(df_in):\n",
    "    \"\"\"A reusable function to apply all preprocessing steps to a DataFrame.\"\"\"\n",
    "    df_processed = df_in.copy()\n",
    "    \n",
    "    # Strip leading/trailing whitespace from all column names\n",
    "    df_processed.columns = df_processed.columns.str.strip()\n",
    "    \n",
    "    # Convert 'values' from object to a numeric type.\n",
    "    df_processed['values'] = pd.to_numeric(df_processed['values'], errors='coerce')\n",
    "\n",
    "    # Handle missing values. For 'pack_of', assume NaN means a single item.\n",
    "    df_processed['pack_of'] = df_processed['pack_of'].fillna(1.0).astype(float)\n",
    "    \n",
    "    # One-hot encode 'units' if the column exists\n",
    "    if 'units' in df_processed.columns:\n",
    "        df_processed['units'] = df_processed['units'].fillna('unknown').astype(str)\n",
    "        # Use reindex to ensure prediction DF has same unit columns as training DF\n",
    "        if 'unit_cols' in globals():\n",
    "             dummies = pd.get_dummies(df_processed['units'], prefix='unit', dtype=float)\n",
    "             df_processed = pd.concat([df_processed.drop('units', axis=1), dummies], axis=1)\n",
    "             # Ensure all columns from training are present, fill missing with 0\n",
    "             for col in unit_cols:\n",
    "                 if col not in df_processed.columns:\n",
    "                     df_processed[col] = 0\n",
    "        else: # First run (training)\n",
    "             df_processed = pd.get_dummies(df_processed, columns=['units'], prefix='unit', dtype=float)\n",
    "            \n",
    "    # Apply text feature engineering\n",
    "    df_processed['description'] = df_processed.apply(create_comprehensive_description, axis=1)\n",
    "    df_processed['image_path'] = df_processed['downloaded_image_name'].apply(lambda x: os.path.join(Config.IMAGE_DIR, str(x)))\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# --- Preprocessing ---\n",
    "df_preprocessed = preprocess_dataframe(df)\n",
    "\n",
    "VALUE_COL = 'values'\n",
    "if VALUE_COL not in df_preprocessed.columns:\n",
    "    raise KeyError(f\"Column '{VALUE_COL}' not found in DataFrame. Please check the column name.\")\n",
    "\n",
    "# Define columns to be used\n",
    "unit_cols = [col for col in df_preprocessed.columns if col.startswith('unit_')]\n",
    "numerical_cols = [VALUE_COL, 'pack_of'] + unit_cols \n",
    "feature_cols = ['description', 'price', 'downloaded_image_name', 'image_path', 'sample_id'] + numerical_cols\n",
    "\n",
    "# Filter for necessary columns and drop rows with essential missing data\n",
    "df_processed = df_preprocessed[feature_cols].copy()\n",
    "df_processed.dropna(subset=['price', 'description', VALUE_COL], inplace=True)\n",
    "df_processed = df_processed[df_processed['description'] != '']\n",
    "\n",
    "print(f\"‚úÖ Created features. Total samples: {len(df_processed)}. Numerical/Categorical features: {numerical_cols}\")\n",
    "\n",
    "train_df, test_df = train_test_split(df_processed, test_size=0.4, random_state=42)\n",
    "print(f\"Data split into {len(train_df)} training and {len(test_df)} testing samples.\")\n",
    "\n",
    "\n",
    "# --- 4. Dataset Class and DataLoaders ---\n",
    "\n",
    "class ProductPriceDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for loading product images, text, and numerical features.\"\"\"\n",
    "    def __init__(self, df, image_transform, tokenizer, numerical_cols, stats, is_predict=False):\n",
    "        self.df = df.copy() \n",
    "        self.image_transform = image_transform\n",
    "        self.tokenizer = tokenizer\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.stats = stats\n",
    "        self.is_predict = is_predict\n",
    "        self.value_col_name = numerical_cols[0] \n",
    "\n",
    "        # Pre-calculate normalized values for efficiency\n",
    "        for col in [self.value_col_name, 'pack_of']:\n",
    "            mean = self.stats[col]['mean']\n",
    "            std = self.stats[col]['std']\n",
    "            self.df[f'{col}_normalized'] = (self.df[col] - mean) / (std + 1e-6)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try:\n",
    "            image = self.image_transform(Image.open(row['image_path']).convert('RGB'))\n",
    "        except (FileNotFoundError, UnboundLocalError, OSError):\n",
    "            return None\n",
    "\n",
    "        text = self.tokenizer(row['description'])[0]\n",
    "        \n",
    "        norm_value = torch.tensor(row[f'{self.value_col_name}_normalized'], dtype=torch.float32)\n",
    "        norm_pack_of = torch.tensor(row['pack_of_normalized'], dtype=torch.float32)\n",
    "        unit_features = torch.tensor(row[[c for c in self.numerical_cols if c.startswith('unit_')]].values.astype(np.float32))\n",
    "        numerical_feats = torch.cat([norm_value.unsqueeze(0), norm_pack_of.unsqueeze(0), unit_features])\n",
    "\n",
    "        if self.is_predict:\n",
    "            return {'image': image, 'text': text, 'numerical': numerical_feats}\n",
    "        else:\n",
    "            log_price = torch.tensor(np.log1p(row['price']), dtype=torch.float32)\n",
    "            return {'image': image, 'text': text, 'numerical': numerical_feats, 'log_price': log_price}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function to filter out None values from the batch.\"\"\"\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch) if batch else None\n",
    "\n",
    "\n",
    "# --- 5. Model, Training, and Evaluation ---\n",
    "\n",
    "class CLIPPricePredictor(nn.Module):\n",
    "    \"\"\"The core model combining CLIP embeddings with numerical features.\"\"\"\n",
    "    def __init__(self, clip_model, numerical_feature_size, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.clip = clip_model\n",
    "        clip_embedding_dim = self.clip.text_projection.shape[1]\n",
    "        combined_dim = (clip_embedding_dim * 2) + numerical_feature_size\n",
    "\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, text, numerical_feats):\n",
    "        with torch.no_grad():\n",
    "            image_features = self.clip.encode_image(image)\n",
    "            text_features = self.clip.encode_text(text)\n",
    "\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        combined = torch.cat([image_features, text_features, numerical_feats], dim=1)\n",
    "        return self.regression_head(combined).squeeze(-1)\n",
    "\n",
    "class EarlyStopper:\n",
    "    \"\"\"Stops training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss, model):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            print(\"‚úÖ Validation loss decreased, saving model checkpoint.\")\n",
    "            torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"üõë Early stopping triggered!\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def calculate_smape(preds, targets):\n",
    "    \"\"\"Calculates Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "    numerator = torch.abs(preds - targets)\n",
    "    denominator = (torch.abs(targets) + torch.abs(preds)) / 2\n",
    "    return (torch.mean(numerator / (denominator + 1e-8)) * 100).item()\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, scheduler, loss_fn, config):\n",
    "    \"\"\"The main training and validation loop.\"\"\"\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_smape': []}\n",
    "    early_stopper = EarlyStopper(patience=config.PATIENCE, min_delta=config.MIN_DELTA)\n",
    "\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Training]\")\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            if batch is None: continue\n",
    "\n",
    "            images = batch['image'].to(config.DEVICE)\n",
    "            texts = batch['text'].to(config.DEVICE)\n",
    "            numerical = batch['numerical'].to(config.DEVICE)\n",
    "            log_prices = batch['log_price'].to(config.DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_log_prices = model(images, texts, numerical)\n",
    "            loss = loss_fn(pred_log_prices, log_prices)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'log_huber_loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss, total_val_smape = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Validation]\"):\n",
    "                if batch is None: continue\n",
    "\n",
    "                images = batch['image'].to(config.DEVICE)\n",
    "                texts = batch['text'].to(config.DEVICE)\n",
    "                numerical = batch['numerical'].to(config.DEVICE)\n",
    "                log_prices = batch['log_price'].to(config.DEVICE)\n",
    "\n",
    "                pred_log_prices = model(images, texts, numerical)\n",
    "                total_val_loss += loss_fn(pred_log_prices, log_prices).item()\n",
    "\n",
    "                true_prices = torch.expm1(log_prices)\n",
    "                pred_prices = torch.expm1(pred_log_prices)\n",
    "                total_val_smape += calculate_smape(pred_prices, true_prices)\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_smape = total_val_smape / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_smape'].append(avg_val_smape)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{config.EPOCHS} -> Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val SMAPE: {avg_val_smape:.2f}% | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "        scheduler.step()\n",
    "        if early_stopper.early_stop(avg_val_loss, model):\n",
    "            break\n",
    "\n",
    "    print(\"Loading best model state from training checkpoint.\")\n",
    "    model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "    return history, model\n",
    "\n",
    "\n",
    "# --- 6. Main Execution Block ---\n",
    "# if __name__ == '__main__':\n",
    "#     # Initialize CLIP model, tokenizer, and image transformations\n",
    "#     clip_model, _, base_preprocess = open_clip.create_model_and_transforms(\n",
    "#         Config.MODEL_NAME, pretrained=Config.PRETRAINED_CHECKPOINT, device=Config.DEVICE\n",
    "#     )\n",
    "#     tokenizer = open_clip.get_tokenizer(Config.MODEL_NAME)\n",
    "\n",
    "#     # Add data augmentation for the training set\n",
    "#     train_preprocess = transforms.Compose([\n",
    "#         transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "#         transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "#         base_preprocess,\n",
    "#     ])\n",
    "\n",
    "#     # Calculate normalization stats ONLY from the training data\n",
    "#     stats = {\n",
    "#         VALUE_COL: {'mean': train_df[VALUE_COL].mean(), 'std': train_df[VALUE_COL].std()},\n",
    "#         'pack_of': {'mean': train_df['pack_of'].mean(), 'std': train_df['pack_of'].std()}\n",
    "#     }\n",
    "\n",
    "#     train_dataset = ProductPriceDataset(train_df, train_preprocess, tokenizer, numerical_cols, stats)\n",
    "#     test_dataset = ProductPriceDataset(test_df, base_preprocess, tokenizer, numerical_cols, stats)\n",
    "\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "#     # Pass the correct number of numerical features to the model\n",
    "#     NUMERICAL_FEATURE_SIZE = len(numerical_cols)\n",
    "#     model = CLIPPricePredictor(clip_model, numerical_feature_size=NUMERICAL_FEATURE_SIZE).to(Config.DEVICE)\n",
    "    \n",
    "#     for param in model.clip.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "#     optimizer = torch.optim.AdamW([\n",
    "#         {'params': model.clip.parameters(), 'lr': Config.CLIP_LR},\n",
    "#         {'params': model.regression_head.parameters(), 'lr': Config.HEAD_LR}\n",
    "#     ], weight_decay=Config.WEIGHT_DECAY)\n",
    "\n",
    "#     loss_fn = nn.HuberLoss()\n",
    "#     scheduler = CosineAnnealingLR(optimizer, T_max=Config.EPOCHS, eta_min=1e-8)\n",
    "\n",
    "#     # Run training\n",
    "#     training_history, best_model = train_and_evaluate(model, train_loader, test_loader, optimizer, scheduler, loss_fn, Config)\n",
    "\n",
    "#     # --- 7. Save Final Model and Plot Results ---\n",
    "#     print(\"\\n--- Training Finished ---\")\n",
    "#     save_finetuned_model(best_model, stats, numerical_cols, Config.MODEL_SAVE_PATH)\n",
    "    \n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "#     epochs_ran = len(training_history['train_loss'])\n",
    "\n",
    "#     ax1.plot(range(epochs_ran), training_history['train_loss'], label='Training Loss (Huber)', marker='o')\n",
    "#     ax1.plot(range(epochs_ran), training_history['val_loss'], label='Validation Loss (Huber)', marker='o')\n",
    "#     ax1.set_title('Training and Validation Loss', fontsize=14); ax1.set_xlabel('Epochs'); ax1.set_ylabel('Loss'); ax1.legend(); ax1.grid(True)\n",
    "\n",
    "#     ax2.plot(range(epochs_ran), training_history['val_smape'], label='Validation SMAPE', color='orange', marker='o')\n",
    "#     ax2.set_title('Validation SMAPE', fontsize=14); ax2.set_xlabel('Epochs'); ax2.set_ylabel('SMAPE (%)'); ax2.legend(); ax2.grid(True)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# =========================================================================================\n",
    "# --- üöÄ NEW: Additional Functions for Saving and Prediction üöÄ ---\n",
    "# =========================================================================================\n",
    "\n",
    "def save_finetuned_model(model, stats, numerical_cols, save_path):\n",
    "    \"\"\"\n",
    "    Saves the fine-tuned model's state, normalization stats, and numerical column info.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained model object.\n",
    "        stats (dict): Dictionary containing mean/std for numerical columns.\n",
    "        numerical_cols (list): List of numerical column names used for training.\n",
    "        save_path (str): Path to save the model file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to hold everything needed for inference\n",
    "    model_package = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'stats': stats,\n",
    "        'numerical_cols': numerical_cols,\n",
    "        'config': {\n",
    "            'MODEL_NAME': Config.MODEL_NAME,\n",
    "            'PRETRAINED_CHECKPOINT': Config.PRETRAINED_CHECKPOINT\n",
    "        }\n",
    "    }\n",
    "    torch.save(model_package, save_path)\n",
    "    print(f\"‚úÖ Model package saved successfully to: {save_path}\")\n",
    "\n",
    "def predict_from_df(df_to_predict, model_path, output_csv_path=\"predictions.csv\"):\n",
    "    \"\"\"\n",
    "    Predicts prices for a given DataFrame using a saved fine-tuned model.\n",
    "    \n",
    "    Args:\n",
    "        df_to_predict (pd.DataFrame): DataFrame with the same structure as the training data.\n",
    "        model_path (str): Path to the saved model package (.pth file).\n",
    "        output_csv_path (str): Path to save the final CSV with predictions.\n",
    "        \n",
    "    Returns:\n",
    "        str: The path to the generated predictions CSV file.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Prediction Process ---\")\n",
    "    \n",
    "    # --- 1. Load Model and Configuration ---\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at: {model_path}\")\n",
    "        \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # ‚úÖ FIXED: Added weights_only=False to allow loading the full dictionary\n",
    "    model_package = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    model_config = model_package['config']\n",
    "    stats = model_package['stats']\n",
    "    numerical_cols_loaded = model_package['numerical_cols']\n",
    "    \n",
    "    # Initialize the base CLIP model and preprocessor\n",
    "    clip_model, _, base_preprocess = open_clip.create_model_and_transforms(\n",
    "        model_config['MODEL_NAME'], pretrained=model_config['PRETRAINED_CHECKPOINT'], device=device\n",
    "    )\n",
    "    tokenizer = open_clip.get_tokenizer(model_config['MODEL_NAME'])\n",
    "    \n",
    "    # Initialize our custom model architecture and load the saved weights\n",
    "    NUMERICAL_FEATURE_SIZE = len(numerical_cols_loaded)\n",
    "    prediction_model = CLIPPricePredictor(clip_model, numerical_feature_size=NUMERICAL_FEATURE_SIZE).to(device)\n",
    "    prediction_model.load_state_dict(model_package['model_state_dict'])\n",
    "    prediction_model.eval() # Set model to evaluation mode\n",
    "    \n",
    "    print(\"‚úÖ Model and configuration loaded.\")\n",
    "\n",
    "    # --- 2. Preprocess the Input DataFrame ---\n",
    "    # Ensure the global 'unit_cols' from training is used for consistent one-hot encoding\n",
    "    global unit_cols\n",
    "    unit_cols = [col for col in numerical_cols_loaded if col.startswith('unit_')]\n",
    "    \n",
    "    df_pred_processed = preprocess_dataframe(df_to_predict)\n",
    "    \n",
    "    # Filter out any rows that have missing essential data after preprocessing\n",
    "    df_pred_processed.dropna(subset=['description', 'values'], inplace=True)\n",
    "    df_pred_processed = df_pred_processed[df_pred_processed['description'] != '']\n",
    "    \n",
    "    # Store sample_ids to merge back later, ensuring order is maintained\n",
    "    original_sample_ids = df_pred_processed['sample_id'].tolist()\n",
    "    \n",
    "    print(f\"‚úÖ Input data preprocessed. Predicting on {len(df_pred_processed)} samples.\")\n",
    "\n",
    "    # --- 3. Create Dataset and DataLoader ---\n",
    "    pred_dataset = ProductPriceDataset(\n",
    "        df_pred_processed, \n",
    "        base_preprocess, \n",
    "        tokenizer, \n",
    "        numerical_cols_loaded, \n",
    "        stats,\n",
    "        is_predict=True # Set flag to not look for 'price' column\n",
    "    )\n",
    "    \n",
    "    pred_loader = DataLoader(\n",
    "        pred_dataset, \n",
    "        batch_size=Config.BATCH_SIZE * 2, # Use a larger batch size for faster inference\n",
    "        shuffle=False, \n",
    "        num_workers= Config.NUM_WORKERS , \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # --- 4. Run Inference ---\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(pred_loader, desc=\"Generating Predictions\"):\n",
    "            if batch is None: continue\n",
    "            \n",
    "            images = batch['image'].to(device)\n",
    "            texts = batch['text'].to(device)\n",
    "            numerical = batch['numerical'].to(device)\n",
    "            \n",
    "            pred_log_prices = prediction_model(images, texts, numerical)\n",
    "            \n",
    "            # Convert log prices back to actual prices\n",
    "            pred_prices = torch.expm1(pred_log_prices).cpu().numpy()\n",
    "            all_predictions.extend(pred_prices)\n",
    "    \n",
    "    print(\"‚úÖ Inference complete.\")\n",
    "\n",
    "    # --- 5. Format and Save Output ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'sample_id': original_sample_ids,\n",
    "        'price': all_predictions\n",
    "    })\n",
    "    \n",
    "    # Format the price to two decimal places\n",
    "    results_df['price'] = results_df['price'].round(2)\n",
    "    \n",
    "    results_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"üéâ Predictions saved successfully to: {output_csv_path}\")\n",
    "    \n",
    "    return output_csv_path\n",
    "\n",
    "# Example of how you would use the prediction function (do not run this part during training)\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    # ... (after training completes and model is saved) ...\n",
    "    \n",
    "    # 1. Load a new DataFrame you want to predict prices for\n",
    "    # new_data_df = pd.read_csv('path/to/your/new_data.csv')\n",
    "    \n",
    "    # 2. Define the path to your saved model\n",
    "    # saved_model_path = 'final_clip_price_model.pth'\n",
    "    \n",
    "    # 3. Call the prediction function\n",
    "    # prediction_csv_file = predict_from_df(new_data_df, saved_model_path, output_csv_path=\"my_new_predictions.csv\")\n",
    "    \n",
    "    # print(f\"Find your results in: {prediction_csv_file}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # ... (after training completes and model is saved) ...\n",
    "    \n",
    "    # 1. Load a new DataFrame you want to predict prices for\n",
    "    # new_data_df = pd.read_csv('path/to/your/new_data.csv')\n",
    "    new_data_df = df\n",
    "    # 2. Define the path to your saved model\n",
    "    saved_model_path = 'final_clip_price_model.pth'\n",
    "    \n",
    "    # 3. Call the prediction function\n",
    "    prediction_csv_file = predict_from_df(new_data_df, saved_model_path, output_csv_path=\"my_new_predictions.csv\")\n",
    "    \n",
    "    print(f\"Find your results in: {prediction_csv_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
